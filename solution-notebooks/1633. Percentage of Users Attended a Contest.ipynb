{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e32cc81-b077-4f7d-83ff-a19e973c03b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType\n",
    "from pyspark.sql.functions import col,count,round\n",
    "\n",
    "spark = SparkSession.builder.appName(\"app\").master(\"local[2]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "950ad8e2-c415-4f91-8c50-204e834fbaaa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n|user_id|user_name|\n+-------+---------+\n|      6|    Alice|\n|      2|      Bob|\n|      7|     Alex|\n+-------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"user_id\",IntegerType(),False),\n",
    "    StructField(\"user_name\",StringType(),False)\n",
    "])\n",
    "\n",
    "data = [\n",
    "    ( 6       , \"Alice\"  )   ,\n",
    "    ( 2       , \"Bob\"    )   ,\n",
    "    ( 7       , \"Alex\"   )  \n",
    "]\n",
    "\n",
    "users = spark.createDataFrame(data,schema)\n",
    "users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce0ec815-3dcf-4652-95d5-def2ca5998db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n|contest_id|user_id|\n+----------+-------+\n|       215|      6|\n|       209|      2|\n|       208|      2|\n|       210|      6|\n|       208|      6|\n|       209|      7|\n|       209|      6|\n|       215|      7|\n|       208|      7|\n|       210|      2|\n|       207|      2|\n|       210|      7|\n+----------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"contest_id\",IntegerType(),False),\n",
    "    StructField(\"user_id\",IntegerType(),False)\n",
    "])\n",
    "data = [\n",
    "( 215        , 6     )  ,\n",
    "( 209        , 2     )  ,\n",
    "( 208        , 2     )  ,\n",
    "( 210        , 6     )  ,\n",
    "( 208        , 6     )  ,\n",
    "( 209        , 7     )  ,\n",
    "( 209        , 6     )  ,\n",
    "( 215        , 7     )  ,\n",
    "( 208        , 7     )  ,\n",
    "( 210        , 2     )  ,\n",
    "( 207        , 2     )  ,\n",
    "( 210        , 7     )  \n",
    "]\n",
    "\n",
    "register = spark.createDataFrame(data,schema)\n",
    "register.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "414e9c41-9816-4cfc-af24-010fae819b83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n|contest_id|percentage|\n+----------+----------+\n|       208|     100.0|\n|       209|     100.0|\n|       210|     100.0|\n|       215|     66.67|\n|       207|     33.33|\n+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Write a solution to find the percentage of the users registered in each contest rounded to two decimals.\n",
    "# Return the result table ordered by percentage in descending order. In case of a tie, order it by contest_id in ascending order.\n",
    "\n",
    "total_users = users.count()\n",
    "register.groupBy(\"contest_id\").agg(round((100*count(\"user_id\")/total_users),2).alias(\"percentage\")).sort(col(\"percentage\").desc(),\"contest_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "774a1dbe-6471-4a5a-89db-dac03dd881b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n|contest_id|percentage|\n+----------+----------+\n|       208|     100.0|\n|       209|     100.0|\n|       210|     100.0|\n|       215|     66.67|\n|       207|     33.33|\n+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "users.createOrReplaceTempView(\"u\")\n",
    "register.createOrReplaceTempView(\"r\")\n",
    "spark.sql(\"select contest_id, round(100*count(*)/(select count(*) from u),2) as percentage from r group by 1 order by 2 desc,1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ed5bb14-b8da-4c1a-ab27-fbbce9b503fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "The spark context has stopped and the driver is restarting. Your notebook will be automatically reattached.",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "039d423f-593c-4637-85f5-df2230741d6e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1633. Percentage of Users Attended a Contest",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
