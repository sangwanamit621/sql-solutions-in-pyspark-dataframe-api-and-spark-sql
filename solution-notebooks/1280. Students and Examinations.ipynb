{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dd0e786-bd83-4b2b-9081-510310f6ddfe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import StructField,StructType,StringType,IntegerType\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "spark = SparkSession.builder.appName(\"app\").master(\"local[2]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f8e33d7-ee2c-409c-968c-8182431c36d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n|student_id|student_name|\n+----------+------------+\n|         1|       Alice|\n|         2|         Bob|\n|        13|        John|\n|         6|        Alex|\n+----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"student_id\",IntegerType(),False),\n",
    "    StructField(\"student_name\",StringType(),False)\n",
    "])\n",
    "data = [\n",
    "    ( 1          , \"Alice\"       ) ,\n",
    "    ( 2          , \"Bob\"         ) ,\n",
    "    ( 13         , \"John\"        ) ,\n",
    "    ( 6          , \"Alex\"        ) \n",
    "]\n",
    "stu = spark.createDataFrame(data,schema)\n",
    "stu.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "391b24f0-8dfc-4d7d-bd19-30328f449248",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n|subject_name|\n+------------+\n|        Math|\n|     Physics|\n| Programming|\n+------------+\n\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"subject_name\",StringType(),False)\n",
    "])\n",
    "data = [\n",
    "    (\"Math\",),\n",
    "    (\"Physics\",),\n",
    "    (\"Programming\",)\n",
    "]\n",
    "sub = spark.createDataFrame(data,schema)\n",
    "sub.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1d59def-33c6-4677-a359-428be122d04b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n|student_id|subject_name|\n+----------+------------+\n|         1|        Math|\n|         1|     Physics|\n|         1| Programming|\n|         2| Programming|\n|         1|     Physics|\n|         1|        Math|\n|        13|        Math|\n|        13| Programming|\n|        13|     Physics|\n|         2|        Math|\n|         1|        Math|\n+----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"student_id\",IntegerType(),False),\n",
    "    StructField(\"subject_name\",StringType(),False)\n",
    "])\n",
    "data = [\n",
    "    ( 1          , \"Math\"         ),\n",
    "    ( 1          , \"Physics\"      ),\n",
    "    ( 1          , \"Programming\"  ),\n",
    "    ( 2          , \"Programming\"  ),\n",
    "    ( 1          , \"Physics\"      ),\n",
    "    ( 1          , \"Math\"         ),\n",
    "    ( 13         , \"Math\"         ),\n",
    "    ( 13         , \"Programming\"  ),\n",
    "    ( 13         , \"Physics\"      ),\n",
    "    ( 2          , \"Math\"         ),\n",
    "    ( 1          , \"Math\"         )]\n",
    "\n",
    "exam = spark.createDataFrame(data,schema)\n",
    "exam.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b369a05-b6b5-47bd-bf32-86672014e356",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+------------+--------------+\n|student_id|student_name|subject_name|attended_exams|\n+----------+------------+------------+--------------+\n|         1|       Alice|        Math|             3|\n|         1|       Alice|     Physics|             2|\n|         1|       Alice| Programming|             1|\n|         2|         Bob|        Math|             1|\n|         2|         Bob|     Physics|             0|\n|         2|         Bob| Programming|             1|\n|         6|        Alex|        Math|             0|\n|         6|        Alex|     Physics|             0|\n|         6|        Alex| Programming|             0|\n|        13|        John|        Math|             1|\n|        13|        John|     Physics|             1|\n|        13|        John| Programming|             1|\n+----------+------------+------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Write a solution to find the number of times each student attended each exam.\n",
    "# Return the result table ordered by student_id and subject_name.\n",
    "stu_sub = stu.crossJoin(sub)\n",
    "stu_sub.join(exam,((stu_sub.student_id==exam.student_id) & (stu_sub.subject_name==exam.subject_name)),'left').groupBy(stu_sub.student_id,stu_sub.student_name,stu_sub.subject_name)\\\n",
    "    .agg(count(exam.student_id).alias(\"attended_exams\")).orderBy(stu_sub.student_id,stu_sub.subject_name).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a900d6e-c369-460b-aa76-8bed9dbce16d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------+\n|student_id|subject_name|attended_exams|\n+----------+------------+--------------+\n|         1|        Math|             3|\n|         1|     Physics|             2|\n|         1| Programming|             1|\n|         2|        Math|             1|\n|         2|     Physics|             0|\n|         2| Programming|             1|\n|         6|        Math|             0|\n|         6|     Physics|             0|\n|         6| Programming|             0|\n|        13|        Math|             1|\n|        13|     Physics|             1|\n|        13| Programming|             1|\n+----------+------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "stu.createOrReplaceTempView(\"stu\")\n",
    "sub.createOrReplaceTempView(\"sub\")\n",
    "exam.createOrReplaceTempView(\"exam\")\n",
    "\n",
    "spark.sql(\"select stu.student_id,sub.subject_name,coalesce(count(exam.student_id),0) as attended_exams from stu,sub left join exam on stu.student_id=exam.student_id and sub.subject_name=exam.subject_name group by 1,2 order by 1,2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b764d596-741e-4e5d-98bb-679ad57219d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "The spark context has stopped and the driver is restarting. Your notebook will be automatically reattached.",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7454f8a-86de-4d50-8b5e-f8b30028d6b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1280. Students and Examinations",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
