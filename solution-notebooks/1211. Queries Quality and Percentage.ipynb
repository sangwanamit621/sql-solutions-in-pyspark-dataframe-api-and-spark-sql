{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c4ab41c-62b5-4351-be1b-360c0d585ff3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField,IntegerType,StringType\n",
    "from pyspark.sql.functions import col,avg,round,when,sum\n",
    "\n",
    "spark = SparkSession.builder.appName(\"app\").master(\"local[2]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fd17027-babf-403b-8662-cfa691ea3ec6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+--------+------+\n|query_name|          result|position|rating|\n+----------+----------------+--------+------+\n|       Dog|Golden Retriever|       1|     5|\n|       Dog| German Shepherd|       2|     5|\n|       Dog|            Mule|     200|     1|\n|       Cat|         Shirazi|       5|     2|\n|       Cat|         Siamese|       3|     3|\n|       Cat|          Sphynx|       7|     4|\n+----------+----------------+--------+------+\n\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"query_name\",StringType(),False),\n",
    "    StructField(\"result\",StringType(),False),\n",
    "    StructField(\"position\",IntegerType(),False),\n",
    "    StructField(\"rating\",IntegerType(),False)\n",
    "])\n",
    "data = [\n",
    " (\"Dog\"        , \"Golden Retriever\"  , 1        , 5)      ,\n",
    " (\"Dog\"        , \"German Shepherd\"   , 2        , 5)      ,\n",
    " (\"Dog\"        , \"Mule\"              , 200      , 1)      ,\n",
    " (\"Cat\"        , \"Shirazi\"           , 5        , 2)      ,\n",
    " (\"Cat\"        , \"Siamese\"           , 3        , 3)      ,\n",
    " (\"Cat\"        , \"Sphynx\"            , 7        , 4)\n",
    "]\n",
    "query = spark.createDataFrame(data,schema)\n",
    "query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b0e43c1-da2d-453c-ada1-29fc2820977a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---------------------+\n|query_name|ratio|poor_query_percentage|\n+----------+-----+---------------------+\n|       Dog|  2.5|                33.33|\n|       Cat| 0.66|                33.33|\n+----------+-----+---------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# We define query quality as:\n",
    "#     * The average of the ratio between query rating and its position.\n",
    "# We also define poor query percentage as:\n",
    "#     * The percentage of all queries with rating less than 3.\n",
    "# Write a solution to find each query_name, the quality and poor_query_percentage. Both quality and poor_query_percentage should be rounded to 2 decimal places.\n",
    "# Return the result table in any order.\n",
    "\n",
    "query.withColumn(\"quality\",query.rating/query.position)\\\n",
    "    .withColumn(\"poor\",when(query.rating<3,1).otherwise(0))\\\n",
    "    .groupBy(\"query_name\")\\\n",
    "    .agg(round(avg(\"quality\"),2).alias(\"ratio\"),round(100*avg(\"poor\"),2).alias(\"poor_query_percentage\"))\\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df399ba7-38c7-47a8-a044-ffc0ffd0c7a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---------------------+\n|query_name|ratio|poor_query_percentage|\n+----------+-----+---------------------+\n|       Dog|  2.5|                33.33|\n|       Cat| 0.66|                33.33|\n+----------+-----+---------------------+\n\n"
     ]
    }
   ],
   "source": [
    "query.createOrReplaceTempView(\"query\")\n",
    "spark.sql(\"select query_name, round(avg(rating/position),2) as ratio, round(avg(100*case when rating<3 then 1 else 0 end),2) as poor_query_percentage from query group by 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c28a7f1a-0d08-41f5-91a6-40ca7320071e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "The spark context has stopped and the driver is restarting. Your notebook will be automatically reattached.",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "204ce5d8-977d-46f3-9ef7-5fabe213c744",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1211. Queries Quality and Percentage",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
