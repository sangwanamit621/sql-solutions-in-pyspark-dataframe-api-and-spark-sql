{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89e8c88c-2306-4732-ad95-bd4a284d25c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StringType, IntegerType, FloatType, BooleanType, TimestampType, DateType, StructField, StructType\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "\n",
    "spark = SparkSession.builder.appName(\"app\").master(\"localhost[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "558a8c9a-ab01-43f9-8a90-a6e6c52eb09b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+\n|personId|lastName|firstName|\n+--------+--------+---------+\n|       1|    Wang|    Allen|\n|       2|   Alice|      Bob|\n+--------+--------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([StructField('personId',IntegerType(),False),\n",
    "                     StructField('lastName',StringType(),False),\n",
    "                     StructField('firstName',StringType(),False)])\n",
    "\n",
    "data = [(1,\"Wang\",\"Allen\"),(2,\"Alice\",\"Bob\")]\n",
    "person = spark.createDataFrame(data=data,schema=schema)\n",
    "person.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49de7854-fab7-4a6c-b07b-72ef14292e11",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----+-----+\n|addressId|personId|city|state|\n+---------+--------+----+-----+\n|        1|       2| NYC|   NY|\n|        2|       3| CMD|  CAL|\n+---------+--------+----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(1,2,\"NYC\",\"NY\"),\n",
    "        (2,3,\"CMD\",\"CAL\")]\n",
    "\n",
    "schema = StructType([\\\n",
    "    StructField(\"addressId\",IntegerType(),False),\n",
    "    StructField(\"personId\",IntegerType(),False),\n",
    "    StructField(\"city\",StringType(),False),\n",
    "    StructField(\"state\",StringType(),False)\n",
    "])\n",
    "\n",
    "address = spark.createDataFrame(data=data,schema=schema)\n",
    "address.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a60a085b-31e7-435e-acd7-5473cd109225",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----+-----+\n|firstName|lastName|city|state|\n+---------+--------+----+-----+\n|    Allen|    Wang|null| null|\n|      Bob|   Alice| NYC|   NY|\n+---------+--------+----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# 175. Combine Two Tables\n",
    "# Write a solution to report the first name, last name, city, and state of each person in the Person table. If the address of a personId is not present in the Address table, report null instead.\n",
    "# Return the result table in any order.\n",
    "\n",
    "final_df = person.join(address,person.personId==address.personId,how=\"left\").select(person.firstName,person.lastName,address.city,address.state)\n",
    "final_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91db1f28-9a07-4fde-8197-38a1bd84f526",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----+-----+\n|firstName|lastName|city|state|\n+---------+--------+----+-----+\n|    Allen|    Wang|null| null|\n|      Bob|   Alice| NYC|   NY|\n+---------+--------+----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "#Using spark.sql\n",
    "person.createOrReplaceTempView(\"person_sql\")\n",
    "address.createOrReplaceTempView(\"address_sql\")\n",
    "\n",
    "spark.sql(\"select p.firstName,p.lastName,a.city,a.state from person_sql p left join address_sql a on p.personId=a.personId\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d14b5d3-b91a-4169-80c8-fd1669f8b7e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "The spark context has stopped and the driver is restarting. Your notebook will be automatically reattached.",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a220d63-8f6c-4728-8cab-f0a5b8d661ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "175. Combine Two Tables",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
