{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c391a434-7884-4968-ae79-b96300ca3e55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType\n",
    "from pyspark.sql.functions import col,sum\n",
    "\n",
    "spark  = SparkSession.builder.appName(\"app\").master(\"local[2]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb01e528-9fe7-4b2d-b8da-3b367761885b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n| id|    name|\n+---+--------+\n|  1|   Alice|\n|  2|     Bob|\n|  3|    Alex|\n|  4|  Donald|\n|  7|     Lee|\n| 13|Jonathan|\n| 19|   Elvis|\n+---+--------+\n\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id\",IntegerType(),False),\n",
    "    StructField(\"name\",StringType(),False)\n",
    "])\n",
    "\n",
    "data = [\n",
    "    ( 1    , \"Alice\"    ) ,\n",
    "    ( 2    , \"Bob\"      ) ,\n",
    "    ( 3    , \"Alex\"     ) ,\n",
    "    ( 4    , \"Donald\"   ) ,\n",
    "    ( 7    , \"Lee\"      ) ,\n",
    "    ( 13   , \"Jonathan\" ) ,\n",
    "    ( 19   , \"Elvis\"    ) \n",
    "]\n",
    "users = spark.createDataFrame(data,schema)\n",
    "users.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "424e6308-9a5a-42fd-831b-df5a3bf14bbf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+\n| id|user_id|distance|\n+---+-------+--------+\n|  1|      1|     120|\n|  2|      2|     317|\n|  3|      3|     222|\n|  4|      7|     100|\n|  5|     13|     312|\n|  6|     19|      50|\n|  7|      7|     120|\n|  8|     19|     400|\n|  9|      7|     230|\n+---+-------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id\",IntegerType(),False),\n",
    "    StructField(\"user_id\",IntegerType(),False),\n",
    "    StructField(\"distance\",IntegerType(),False)\n",
    "])\n",
    "data = [\n",
    "    ( 1    , 1        , 120  )    ,\n",
    "    ( 2    , 2        , 317  )    ,\n",
    "    ( 3    , 3        , 222  )    ,\n",
    "    ( 4    , 7        , 100  )    ,\n",
    "    ( 5    , 13       , 312  )    ,\n",
    "    ( 6    , 19       , 50   )    ,\n",
    "    ( 7    , 7        , 120  )    ,\n",
    "    ( 8    , 19       , 400  )    ,\n",
    "    ( 9    , 7        , 230  )    \n",
    "]\n",
    "\n",
    "trips = spark.createDataFrame(data,schema)\n",
    "trips.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a4a7d33-4a7b-4fa1-8797-d751b1eaa0a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n|    name|travelled_distance|\n+--------+------------------+\n|   Elvis|               450|\n|     Lee|               450|\n|     Bob|               317|\n|Jonathan|               312|\n|    Alex|               222|\n|   Alice|               120|\n|  Donald|                 0|\n+--------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Write a solution to report the distance traveled by each user. Return the result table ordered by travelled_distance in descending order, \n",
    "# if two or more users traveled the same distance, order them by their name in ascending order.\n",
    "\n",
    "trips.groupBy(\"user_id\").agg(sum(\"distance\").alias(\"travelled_distance\")).join(users,trips.user_id==users.id,\"right\").select(users.name,\"travelled_distance\").fillna(0,[\"travelled_distance\"]).orderBy(col(\"travelled_distance\").desc(),col(\"name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0298afc0-e146-4602-9b53-a6ae1a5a2e9a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n|    name|travelled_distance|\n+--------+------------------+\n|   Elvis|               450|\n|     Lee|               450|\n|     Bob|               317|\n|Jonathan|               312|\n|    Alex|               222|\n|   Alice|               120|\n|  Donald|                 0|\n+--------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "users.createOrReplaceTempView(\"u\")\n",
    "trips.createOrReplaceTempView(\"t\")\n",
    "\n",
    "spark.sql(\"select u.name,coalesce(sum(t.distance),0) as travelled_distance from t right join u on t.user_id=u.id group by u.id,u.name order by 2 desc,1;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c71289f-0919-4a47-9837-a72bc6b9a090",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "The spark context has stopped and the driver is restarting. Your notebook will be automatically reattached.",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9ebce14-8f86-4db5-801e-8b15d683510b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1407. Top Travellers",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
