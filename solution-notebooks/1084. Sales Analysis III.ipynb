{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04f49920-114c-492d-902e-1680b8ca1d23",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType,StringType,DateType\n",
    "from pyspark.sql.functions import col,quarter\n",
    "from datetime import datetime\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"app\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcf38491-3e08-4a3c-b104-d030980dc46d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+\n|product_id|product_name|unit_price|\n+----------+------------+----------+\n|         1|          S8|      1000|\n|         2|          G4|       800|\n|         3|      iPhone|      1400|\n+----------+------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"product_id\",IntegerType(),False),\n",
    "    StructField(\"product_name\",StringType(),False),\n",
    "    StructField(\"unit_price\",IntegerType(),False)\n",
    "])\n",
    "\n",
    "data = [\n",
    "( 1          , \"S8\"           , 1000)       ,\n",
    "( 2          , \"G4\"           , 800 )       ,\n",
    "( 3          , \"iPhone\"       , 1400)\n",
    "]\n",
    "\n",
    "product = spark.createDataFrame(data,schema)\n",
    "product.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dda3ad98-dd81-41d8-917b-5f16b64f3e1e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+--------+-----+\n|seller_id|product_id|buyer_id| sale_date|quantity|price|\n+---------+----------+--------+----------+--------+-----+\n|        1|         1|       1|2019-01-21|       2| 2000|\n|        1|         2|       2|2019-02-17|       1|  800|\n|        2|         2|       3|2019-06-02|       1|  800|\n|        3|         3|       4|2019-05-13|       2| 2800|\n+---------+----------+--------+----------+--------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"seller_id\",IntegerType(),False),\n",
    "    StructField(\"product_id\",IntegerType(),False),\n",
    "    StructField(\"buyer_id\",IntegerType(),False),\n",
    "    StructField(\"sale_date\",DateType(),False),\n",
    "    StructField(\"quantity\",IntegerType(),False),\n",
    "    StructField(\"price\",IntegerType(),False)\n",
    "])\n",
    "\n",
    "data = [\n",
    "(1         , 1          , 1        , datetime(2019,1,21) , 2        , 2000)  ,\n",
    "(1         , 2          , 2        , datetime(2019,2,17) , 1        , 800 )  ,\n",
    "(2         , 2          , 3        , datetime(2019,6,2)  , 1        , 800 )  ,\n",
    "(3         , 3          , 4        , datetime(2019,5,13) , 2        , 2800)\n",
    "]\n",
    "\n",
    "sales = spark.createDataFrame(data,schema)\n",
    "sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bdf78c6-c50d-4512-ad29-24100e6ebef8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n|product_id|product_name|\n+----------+------------+\n|         1|          S8|\n+----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Write a solution to report the products that were only sold in the first quarter of 2019. That is, between 2019-01-01 and 2019-03-31 inclusive.\n",
    "# Return the result table in any order.\n",
    "# products_to_skip = sales.where(quarter(col(\"sale_date\"))>1).select(col(\"product_id\")).distinct().rdd.flatMap(lambda x: x).collect()\n",
    "products_to_skip = sales.where(quarter(col(\"sale_date\"))>1).select(col(\"product_id\")).distinct().rdd.map(lambda x: x[0]).collect()\n",
    "sales.filter(~col(\"product_id\").isin(products_to_skip)).join(product,sales.product_id==product.product_id,\"inner\").select(sales.product_id,\"product_name\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de863619-26e4-47b4-9adf-20579108f989",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n|product_id|product_name|\n+----------+------------+\n|         1|          S8|\n+----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "sales.createOrReplaceTempView(\"s\")\n",
    "product.createOrReplaceTempView(\"p\")\n",
    "spark.sql(\"select distinct s.product_id,p.product_name from s join p using (product_id) where product_id not in(select product_id from s where quarter(sale_date)<>1)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e1823ff-b5b7-48fc-beea-3a164b16af5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "The spark context has stopped and the driver is restarting. Your notebook will be automatically reattached.",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5474c60-8ef1-4eb4-ad3b-6301824598d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1084. Sales Analysis III",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
