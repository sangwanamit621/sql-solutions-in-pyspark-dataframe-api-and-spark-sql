{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a129034-83a4-49bf-b0cd-29a379f7e820",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import StructField,StructType,IntegerType\n",
    "from pyspark.sql.functions import col,when\n",
    "\n",
    "spark = SparkSession.builder.appName(\"app\").master(\"local[3]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b74bc538-e913-4aef-8c77-9ab68074be22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n| id|p_id|\n+---+----+\n|  1|null|\n|  2|   1|\n|  3|   1|\n|  4|   2|\n|  5|   2|\n+---+----+\n\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id\",IntegerType(),False),\n",
    "    StructField(\"p_id\",IntegerType(),True)\n",
    "])\n",
    "data = [\n",
    "( 1  , None) ,\n",
    "( 2  , 1   ) ,\n",
    "( 3  , 1   ) ,\n",
    "( 4  , 2   ) ,\n",
    "( 5  , 2   ) \n",
    "]\n",
    "tree = spark.createDataFrame(data,schema)\n",
    "tree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af88d2cb-56c5-44b9-982e-c6aba4f18920",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n| id| type|\n+---+-----+\n|  1| Root|\n|  2|Inner|\n|  3| Leaf|\n|  4| Leaf|\n|  5| Leaf|\n+---+-----+\n\n"
     ]
    }
   ],
   "source": [
    "p_ids = tree.select(\"p_id\").distinct().dropna().rdd.flatMap(lambda x:x).collect()\n",
    "tree.select(\"id\",when(col(\"p_id\").isNull(),\"Root\").when(col(\"id\").isin(p_ids),\"Inner\").otherwise(\"Leaf\").alias(\"type\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d29cb071-a99e-4b3a-990a-bc78987530f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n| id| type|\n+---+-----+\n|  1| Root|\n|  2|Inner|\n|  3| Leaf|\n|  4| Leaf|\n|  5| Leaf|\n+---+-----+\n\n"
     ]
    }
   ],
   "source": [
    "tree.createOrReplaceTempView(\"tree\")\n",
    "spark.sql(\"select id, case when p_id is null then 'Root' when `id` in (select p_id from tree where p_id is not null) then 'Inner' else 'Leaf' end as type from tree\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31c5090d-0dc1-4bf9-8848-99b54628e171",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "The spark context has stopped and the driver is restarting. Your notebook will be automatically reattached.",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9480a2d6-8250-4953-ae57-08b26e0c84d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "608. Tree Node",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
