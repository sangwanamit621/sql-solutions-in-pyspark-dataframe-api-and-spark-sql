{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f9ec850-b6d7-411e-be10-921033e67c90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import StructField,StructType,IntegerType\n",
    "from pyspark.sql.functions import col,count\n",
    "\n",
    "spark = SparkSession.builder.appName(\"app\").master(\"local[2]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34be60db-bf4f-4268-b18f-3e307a3715f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---------+\n|actor_id|director_id|timestamp|\n+--------+-----------+---------+\n|       1|          1|        0|\n|       1|          1|        1|\n|       1|          1|        2|\n|       1|          2|        3|\n|       1|          2|        4|\n|       2|          1|        5|\n|       2|          1|        6|\n+--------+-----------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"actor_id\",IntegerType(),False),\n",
    "    StructField(\"director_id\",IntegerType(),False),\n",
    "    StructField(\"timestamp\",IntegerType(),False)\n",
    "])\n",
    "\n",
    "data = [\n",
    "    (1           , 1           , 0  )         ,\n",
    "    (1           , 1           , 1  )         ,\n",
    "    (1           , 1           , 2  )         ,\n",
    "    (1           , 2           , 3  )         ,\n",
    "    (1           , 2           , 4  )         ,\n",
    "    (2           , 1           , 5  )         ,\n",
    "    (2           , 1           , 6  ) \n",
    "]\n",
    "\n",
    "actor_dir = spark.createDataFrame(data,schema)\n",
    "actor_dir.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d64268b2-f6c3-487b-b6f1-6d904d69a6de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n|actor_id|director_id|\n+--------+-----------+\n|       1|          1|\n+--------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Write a solution to find all the pairs (actor_id, director_id) where the actor has cooperated with the director at least three times.\n",
    "# Return the result table in any order\n",
    "actor_dir.groupBy([col(\"actor_id\"),col(\"director_id\")]).agg(count(col(\"timestamp\")).alias(\"colab\")).filter(col(\"colab\")>=3).select(\"actor_id\",'director_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "addc314f-4530-41ca-8ce1-67fec99814fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n|actor_id|director_id|\n+--------+-----------+\n|       1|          1|\n+--------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "actor_dir.createOrReplaceTempView(\"ad\")\n",
    "spark.sql(\"select actor_id,director_id from ad group by 1,2 having count(*)>=3\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3932156-44f3-4faf-ad74-f138c0c0dd86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "The spark context has stopped and the driver is restarting. Your notebook will be automatically reattached.",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6397edd7-0a9c-429b-aeba-9e66e2f2f76a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1050. Actors and Directors Who Cooperated At Least Three Times",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
