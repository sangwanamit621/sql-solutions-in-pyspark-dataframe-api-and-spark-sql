{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c16e534-71f8-46b1-87ab-982a08593d00",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField,StringType,IntegerType\n",
    "from pyspark.sql.functions import col, avg,round\n",
    "\n",
    "spark = SparkSession.builder.appName(\"app\").master(\"local[2]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e31ad710-1a6b-4356-92fe-9ac93c42556c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n|project_id|employee_id|\n+----------+-----------+\n|         1|          1|\n|         1|          2|\n|         1|          3|\n|         2|          1|\n|         2|          4|\n+----------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField('project_id',IntegerType(), False),\n",
    "    StructField('employee_id',IntegerType(),False)\n",
    "])\n",
    "\n",
    "data = [\n",
    "    (1           , 1)         ,\n",
    "    (1           , 2)         ,\n",
    "    (1           , 3)         ,\n",
    "    (2           , 1)         ,\n",
    "    (2           , 4)\n",
    "]\n",
    "\n",
    "project = spark.createDataFrame(data,schema)\n",
    "project.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20cee647-3413-4425-8d96-05d38454df05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----------------+\n|employee_id|  name|experience_years|\n+-----------+------+----------------+\n|          1|Khaled|               3|\n|          2|   Ali|               2|\n|          3|  John|               1|\n|          4|   Doe|               2|\n+-----------+------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"employee_id\",IntegerType(),False),\n",
    "    StructField(\"name\",StringType(),False),\n",
    "    StructField(\"experience_years\",IntegerType(),False)\n",
    "])\n",
    "\n",
    "data = [\n",
    " (1         , \"Khaled\" , 3)                ,\n",
    " (2         , \"Ali\"    , 2)                ,\n",
    " (3         , \"John\"   , 1)                ,\n",
    " (4         , \"Doe\"    , 2) \n",
    "]\n",
    "emp = spark.createDataFrame(data,schema)\n",
    "emp.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7df7e360-9d93-441c-a95e-e31ac5cc53eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n|project_id|average_years|\n+----------+-------------+\n|         1|          2.0|\n|         2|          2.5|\n+----------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Write an SQL query that reports the average experience years of all the employees for each project, rounded to 2 digits.\n",
    "# Return the result table in any order.\n",
    "\n",
    "project.join(emp,project.employee_id==emp.employee_id,'inner').groupBy(col(\"project_id\")).agg(round(avg(col(\"experience_years\")),2).alias(\"average_years\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62342644-8f65-400f-bdfd-49ba6232bddb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n|project_id|average_years|\n+----------+-------------+\n|         1|          2.0|\n|         2|          2.5|\n+----------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "project.createOrReplaceTempView(\"p\")\n",
    "emp.createOrReplaceTempView(\"e\")\n",
    "\n",
    "spark.sql(\"select p.project_id, round(avg(e.experience_years),2) as average_years from p join e using(employee_id) group by p.project_id;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "577e8b7c-be4e-4b28-a5d7-c1ca7f74ad55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "The spark context has stopped and the driver is restarting. Your notebook will be automatically reattached.",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e990774-748e-47cf-8e61-17592b091e6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1075. Project Employees I",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
